{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR2oZION7AYe0SOXTjZp1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23005/EU_M_Math/blob/main/Chap08_Cm_01%2C02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cm-01\n",
        "\n",
        "回帰：Yが連続値のときにY = f(x)というモデルを当てはめること。\n",
        "\n",
        "分類：あるデータがどのクラスに属するのかの予測。\n",
        "\n",
        "教師あり学習：学習データに正解を与えた状態で学習させる手法。システムの不正行為の検出やおすすめ製品のパーソナライズなどを実現できる。\n",
        "\n",
        "重回帰分析：複数の説明変数を用いて目的変数との関係を推定する手法。結果に対して各説明変数がどの程度の影響を持つか知りたいときや説明変数を元に将来の結果を予測したい際に活用される。\n",
        "\n",
        "ロジスティック回帰分析：目的変数が0と1からなる2値のデータ、あるいは0から1までの値からなる確率などのデータについて、説明変数を使った式で表す方法。ある事象が起こる確率を予測することが出来る。\n",
        "\n",
        "正則化：過学習を防ぐテクニック。\n",
        "\n",
        "リッジ回帰：重回帰分析に対して重みの2乗で表現されるL2ノルムを用いて正則化を行うことで、モデルの過度な複雑さに罰則を課して過学習を抑制する方法。\n",
        "\n",
        "ラッソ回帰：重回帰分析に対して重みの絶対値の和L1ノルムを用いて正則化を行うことで、モデルの過度な複雑さに罰則を課して過学習を抑制する方法。\n",
        "\n",
        "決定木：分類問題と回帰問題を解く教師ありアルドリズムの一つで与えられたデータに対して次々に条件を設けてデータを段階的に分類していく手法。\n",
        "\n",
        "エントロピー：機械学習で分類を行うモデルを作成した後に、予測値と実際の値との誤差を見るための関数。\n",
        "\n",
        "情報利得：ある集団を複数に分割した際の、分割前後の不純度の差。\n",
        "\n",
        "k-NN法：データをグループ分けするにあたり、対象とするあるデータがどのグループに含まれるかを周囲のデータの多数決で推測するという手法。\n",
        "\n",
        "SVM：信号処理医療アプリケーションや自然言語処理、音声及び画像認識などの多くの分類と回帰の問題にしようされる教師ありアルゴリズム。異なるグループのデータを効率よく分類する手法。\n",
        "\n",
        "ノーフリーランチ：事例の分布などについて、事前情報が無ければあらゆる目的関数について他を常に上回るような学習アルゴリズムは存在しないという定理。\n"
      ],
      "metadata": {
        "id": "dklGrMHwphaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cm-02\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = iris.target, random_state=0)\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train, y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy97TjyVvShc",
        "outputId": "8135a008-153e-4c12-9767-78702d8994f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率(train):0.964\n",
            "正解率(test):0.947\n"
          ]
        }
      ]
    }
  ]
}